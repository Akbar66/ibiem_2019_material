---
title: "Download From Argonne National Labs"
output:
  md_document:
    variant: markdown_github
  html_document:
    toc: false
---
<!-- 
R -e "rmarkdown::render('misc/argonne_download.Rmd', output_format=c('html_document', 'md_document'))" 
R -e "rmarkdown::render('misc/argonne_download.Rmd')" 
-->

># NOTE: This notebook is for example purposes only.  It no longer works because the data is not available for download anymore.

```{r global_options, include=FALSE}
library(knitr)
# rm(list=ls()) ### To clear namespace
opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, eval=FALSE)
```

# Load Libraries
```{r}
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(tibble))
```

# Set up directory to receive data
```{r}
raw.data="/sharedspace/argonne_data"
uncompressed.md5 = file.path(raw.data,"md5_checksum_uncompressed_fastqs.txt")
compressed.md5 = file.path(raw.data,"md5_checksum_compressed_fastqs.txt")

Sys.setenv(RAW_DATA=raw.data)
Sys.setenv(COMPRESSED_MD5=compressed.md5)
Sys.setenv(UNCOMPRESSED_MD5=uncompressed.md5)
dir.create(raw.data, recursive = TRUE, showWarnings = FALSE)
```


# Download Data from Argonne
## Download with wget
These chunks will not work as-is because the one-time URLs have already been used.  New one-time URLs can be obtained by logging in to  https://sequencing.bio.anl.gov/index.html

- `--no-verbose` tells `wget` to *not* print a lot of status information during the download.
- `--content-disposition` tells `wget` to use the file name from the server (otherwise it will name files with the random charracters in the one-time URLs)
- `--directory-prefix` tells `wget` what directory to download the files into


```{bash}
wget --content-disposition --no-verbose \
  --directory-prefix $RAW_DATA \
  http://shock.metagenomics.anl.gov/preauth/pBiK1ZDIkDqGLEibz88c
```

```{bash}
wget --content-disposition --no-verbose \
  --directory-prefix $RAW_DATA \
  http://shock.metagenomics.anl.gov/preauth/IUUT80Lu4aOKKkWLJsRl
```

```{bash}
wget --content-disposition --no-verbose \
  --directory-prefix $RAW_DATA \
  http://shock.metagenomics.anl.gov/preauth/UKdpX2Qk7nszU790SBDn
```

## Make MD5 sum file
Argonne does not provide an MD5sum file, but MD5sums can be copied manually from the download webpage: https://sequencing.bio.anl.gov/index.html

```{r}
tribble(
  ~md5sum, ~file,
  "8d1d121829a8519f404026654c26ba3d", "Undetermined_S0_L001_I1_001.fastq",
  "0a0e4475e81fa0cd2ea3d891064c521f", "Undetermined_S0_L001_R1_001.fastq",
  "b1c1503dd7a05e92ad0eb296e66deadb", "Undetermined_S0_L001_R2_001.fastq",
  "d68f457d872e1aaba215f0b7b7585ec0", "200114_McCumber_16SFW_AS_200110.txt"
) %>%
  write_tsv(uncompressed.md5, col_names = FALSE)
```

## Confirm Downloaded files
```{bash}
cd $RAW_DATA
md5sum -c $UNCOMPRESSED_MD5
```

## Compress FASTQs and generate MD5 sum
```{bash}
cd $RAW_DATA
gzip Undetermined_S0_L001_??_001.fastq
md5sum Undetermined_S0_L001_??_001.fastq.gz 200114_McCumber_16SFW_AS_200110.txt > $COMPRESSED_MD5
```

## Make directory read-only
```{bash}
chmod -R a-w $RAW_DATA
```

# Archive Data
This is only necessary if data isn't already archived on DDS

## Upload data to DDS
```{bash}
ddsclient upload -p IBIEM_2019 $RAW_DATA
```

## Confirm DDS upload
```{bash}
ddsclient upload --dry-run -p IBIEM_2019 $RAW_DATA
```
